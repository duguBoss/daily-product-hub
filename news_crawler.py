import os
import time
import json
import re
import requests
from urllib.parse import urljoin
from openai import OpenAI

# === é…ç½® ===
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")
# å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚æœç¬¬ä¸€ä¸ªå¤±è´¥å°è¯•ç¬¬äºŒä¸ª (å…è´¹æ¨¡å‹ä¸ç¨³å®š)
AI_MODELS = [
    "stepfun/step-3.5-flash:free",
    "z-ai/glm-4.5-air:free"
]
SOURCES = [
    "https://www.ithome.com",
    "https://www.mydrivers.com"
]
OUTPUT_DIR = "data"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "daily_tech_news.json")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENROUTER_API_KEY,
)

def ensure_dir():
    """ç¡®ä¿ data ç›®å½•å­˜åœ¨"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"åˆ›å»ºç›®å½•: {OUTPUT_DIR}")

def save_json_file(data):
    """ä¿å­˜åˆ° data/daily_tech_news.json"""
    ensure_dir()
    try:
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"âœ… æ–‡ä»¶å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

def fetch_jina_content(url):
    """æŠ“å–ç½‘é¡µï¼Œå¢åŠ é‡è¯•å’ŒéªŒè¯"""
    print(f"ğŸŒ æ­£åœ¨è¯·æ±‚ Jina è¯»å–: {url}")
    headers = {
        "X-Return-Format": "markdown",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    for _ in range(2): # é‡è¯•2æ¬¡
        try:
            resp = requests.get(f"https://r.jina.ai/{url}", headers=headers, timeout=30)
            if resp.status_code == 200:
                text = resp.text
                if len(text) < 200:
                    print(f"âš ï¸ è­¦å‘Š: å†…å®¹è¿‡çŸ­ ({len(text)} å­—ç¬¦)ï¼Œå¯èƒ½æ˜¯è¢«åçˆ¬æ‹¦æˆªéªŒè¯ç ã€‚")
                    return ""
                return text
        except Exception as e:
            print(f"   è¯·æ±‚å‡ºé”™: {e}")
            time.sleep(2)
    return ""

def clean_json_string(text):
    """æ·±åº¦æ¸…æ´— JSON å­—ç¬¦ä¸²"""
    if not text: return ""
    text = text.strip()
    # ç§»é™¤ Markdown ä»£ç å—
    match = re.search(r'```(?:json)?\s*(.*?)\s*```', text, re.DOTALL | re.IGNORECASE)
    if match: text = match.group(1).strip()
    
    # å¯»æ‰¾æœ€å¤–å±‚çš„ [] æˆ– {}
    s1, s2 = text.find('['), text.find('{')
    start = -1
    if s1 != -1 and s2 != -1: start = min(s1, s2)
    elif s1 != -1: start = s1
    elif s2 != -1: start = s2
    
    if start != -1:
        # ç®€å•æˆªå–ï¼Œå‡è®¾æœ€åæ˜¯å¯¹åº”çš„ç»“æŸç¬¦
        text = text[start:]
        e1, e2 = text.rfind(']'), text.rfind('}')
        end = -1
        if e1 != -1 and e2 != -1: end = max(e1, e2)
        elif e1 != -1: end = e1
        elif e2 != -1: end = e2
        if end != -1:
            text = text[:end+1]
            
    return text

def call_ai_with_retry(messages):
    """å°è¯•è°ƒç”¨ AIï¼Œå¤±è´¥åˆ™åˆ‡æ¢æ¨¡å‹"""
    for model in AI_MODELS:
        try:
            # print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨æ¨¡å‹: {model}")
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.3 # é™ä½éšæœºæ€§
            )
            content = resp.choices[0].message.content
            if content:
                return content
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹ {model} è°ƒç”¨å¤±è´¥: {e}")
            time.sleep(1)
    return ""

def get_hot_news_links(all_markdown):
    """æå–çƒ­ç‚¹æ–°é—»é“¾æ¥"""
    print("ğŸ§  æ­£åœ¨åˆ†æçƒ­ç‚¹æ–°é—»...")
    
    # ä¸ºäº†é˜²æ­¢ Gemini å…è´¹ç‰ˆè¿‡è½½ï¼Œè¿™é‡Œä¸ä½¿ç”¨å¤šè½®å¯¹è¯ï¼Œç›´æ¥æˆªå– Markdown çš„å‰ 15000 å­—ç¬¦
    # å…è´¹ç‰ˆå¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡éå¸¸æ…¢ä¸”å®¹æ˜“è¶…æ—¶ï¼Œ15000å­—ç¬¦é€šå¸¸åŒ…å«äº†å½“å¤©æ‰€æœ‰é‡è¦æ–°é—»æ ‡é¢˜
    shortened_md = all_markdown[:15000]
    
    prompt = f"""
    åŸºäºä»¥ä¸‹ç§‘æŠ€æ–°é—»ç½‘ç«™çš„å†…å®¹ï¼Œæå–ä»Šæ—¥æœ€çƒ­é—¨çš„5æ¡ã€ç¡¬ä»¶/æ•°ç äº§å“ã€‘æ–°é—»ã€‚
    
    å†…å®¹æ¥æºï¼š
    {shortened_md}
    
    è¦æ±‚ï¼š
    1. å¿…é¡»æ˜¯ç¡¬ä»¶äº§å“ï¼ˆæ‰‹æœºã€æ˜¾å¡ã€èŠ¯ç‰‡ã€ç”µè„‘ç­‰ï¼‰ã€‚
    2. è¿”å›æ ‡å‡† JSON æ•°ç»„ï¼Œæ—  Markdown æ ‡è®°ã€‚
    3. æ ¼å¼ï¼š[{{"title": "æ ‡é¢˜", "url": "é“¾æ¥"}}]
    4. å¦‚æœé“¾æ¥æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè¯·ä¿ç•™åŸæ ·ã€‚
    """
    
    messages = [{"role": "user", "content": prompt}]
    resp = call_ai_with_retry(messages)
    
    try:
        json_str = clean_json_string(resp)
        data = json.loads(json_str)
        
        # ä¿®æ­£é“¾æ¥
        valid_data = []
        for item in data:
            u = item.get("url", "")
            if not u: continue
            if u.startswith("/"):
                # ç®€å•è¡¥å…¨
                base = "https://www.ithome.com" if "ithome" in u or "html" in u else "https://www.mydrivers.com"
                u = urljoin(base, u)
            valid_data.append({"title": item["title"], "url": u})
        return valid_data[:5]
    except Exception as e:
        print(f"âŒ è§£æçƒ­ç‚¹åˆ—è¡¨å¤±è´¥: {e}")
        print(f"AI åŸæ–‡: {resp}")
        return []

def get_article_details(title, url):
    """æå–å•ç¯‡è¯¦æƒ…"""
    print(f"  -> åˆ†æè¯¦æƒ…: {title}")
    md = fetch_jina_content(url)
    if not md: return None
    
    # æˆªå–è¯¦æƒ…é¡µå‰ 8000 å­—ç¬¦é˜²æ­¢ tokens æº¢å‡º
    md_short = md[:8000]
    
    prompt = f"""
    é˜…è¯»æ–‡ç« ï¼š{md_short}
    
    ä»»åŠ¡ï¼š
    1. æ€»ç»“æ ¸å¿ƒå†…å®¹ï¼ˆ200-400å­—ï¼‰ã€‚
    2. æå–æ–‡ä¸­ç¬¬ä¸€å¼ ç›¸å…³äº§å“å›¾ç‰‡çš„é“¾æ¥ï¼ˆä»¥httpå¼€å¤´ï¼‰ã€‚
    
    è¿”å› JSONï¼š
    {{"content": "æ€»ç»“å†…å®¹...", "images": ["å›¾ç‰‡é“¾æ¥"]}}
    """
    
    resp = call_ai_with_retry([{"role": "user", "content": prompt}])
    try:
        json_str = clean_json_string(resp)
        return json.loads(json_str)
    except:
        return {"content": "æå–å¤±è´¥", "images": []}

def main():
    # 1. é¢„å…ˆåˆ›å»ºç©ºæ–‡ä»¶ï¼Œé˜²æ­¢ Workflow æŠ¥é”™
    ensure_dir()
    if not os.path.exists(OUTPUT_FILE):
        save_json_file([])

    if not OPENROUTER_API_KEY:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENROUTER_API_KEY")
        return

    # 2. æŠ“å–ä¸»é¡µ
    full_content = ""
    for site in SOURCES:
        text = fetch_jina_content(site)
        print(f"   ç«™ç‚¹ {site} è·å–é•¿åº¦: {len(text)} å­—ç¬¦")
        if len(text) > 500:
            full_content += f"\næ¥æº {site}:\n{text}\n"
    
    if not full_content:
        print("âŒ æ‰€æœ‰ç«™ç‚¹æŠ“å–å†…å®¹å‡ä¸ºç©ºï¼Œå¯èƒ½æ˜¯ IP è¢«å°é”ã€‚")
        return

    # 3. æå–åˆ—è¡¨
    news_list = get_hot_news_links(full_content)
    print(f"âœ… æå–åˆ° {len(news_list)} æ¡æ–°é—»")

    # 4. å¾ªç¯æå–è¯¦æƒ…
    final_result = []
    for news in news_list:
        details = get_article_details(news["title"], news["url"])
        if details:
            final_result.append({
                "èµ„è®¯æ ‡é¢˜": news["title"],
                "å†…å®¹": details.get("content", ""),
                "é…å›¾": details.get("images", [])
            })
        time.sleep(2) # é¿å…é€Ÿç‡é™åˆ¶

    # 5. ä¿å­˜ç»“æœ
    if final_result:
        save_json_file(final_result)
        print(json.dumps(final_result, ensure_ascii=False, indent=2))
    else:
        print("âš ï¸ æœ€ç»ˆç»“æœä¸ºç©ºï¼Œæœªè¿›è¡Œä¿å­˜è¦†ç›–ã€‚")

if __name__ == "__main__":
    main()
